{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6025bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'webdriver_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Service\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Service \u001b[38;5;28;01mas\u001b[39;00m ChromeService\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwebdriver_manager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChromeDriverManager\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Base URL for company job listings\u001b[39;00m\n\u001b[1;32m     15\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.bain.com/careers/find-a-role/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Base URL for company job listings\n",
    "base_url = 'https://www.bain.com/careers/find-a-role/'\n",
    "\n",
    "# TODO: Define the pull_company_name function\n",
    "def pull_company_name(base_url, all_links, job_links):\n",
    "    \"\"\"\n",
    "    Extracts job links from the company careers page.\n",
    "\n",
    "    Parameters:\n",
    "    base_url (str): The base URL of the company careers page.\n",
    "    all_links (list): List of all links on the current page.\n",
    "    job_links (list): List of collected job links.\n",
    "\n",
    "    Returns:\n",
    "    list: Updated list of job links.\n",
    "    \"\"\"\n",
    "\n",
    "    for link in all_links:\n",
    "        # TODO: Check if the link contains a certain pattern and is not already in job_links\n",
    "        # Append the link to job_links if it meets the criteria\n",
    "        \n",
    "        href = link['href'] # extract href\n",
    "        # check for 'jobid' in hrefs to find proper job_links\n",
    "        # check for duplicates before appending to return value\n",
    "\n",
    "        # check_url = base_url + href[href.find('position'):]\n",
    "        target_url = base_url + href[href.find('position'):]\n",
    "        if href and 'jobid' in href and target_url not in job_links:\n",
    "            # parse target href and concat with base_url for proper url/link\n",
    "            # append to job_links list \n",
    "            # FUNCTION IS CALLED 'pull_company_name' SO MAYBE ADD COMPANY NAME BEFORE LINK LATER? OR MAYBE I DID THIS WRONG AND THEY WANT A LIST OF CLICKABLE LINKS?? IS THAT POSSIBLE? ANYWAY COMEBACK LATER!\n",
    "            job_links.append(target_url)\n",
    "\n",
    "    # print('joblinks',job_links)        \n",
    "    return job_links\n",
    "\n",
    "# TODO: Define the button_company_name function\n",
    "def button_company_name(driver, page, outer_loop_break, all_links):\n",
    "    \"\"\"\n",
    "    Handles pagination by clicking the \"next page\"/\"load more\" button.\n",
    "\n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    page (int): The current page number. (optional)\n",
    "    outer_loop_break (bool): Flag to indicate when to stop scraping.\n",
    "    all_links (list): List of all links on the current page.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated page number and outer_loop_break flag.\n",
    "    \n",
    "    \"\"\"\n",
    "    # URL changes when clicking 'load more' but not like how i want...\n",
    "    # POSSIBLE IDEA?? -> compare curr number of job links on page to total number of job links class=\"search__counter\"\n",
    "    counted_roles = driver.find_element(By.CLASS_NAME, 'search__counter').text\n",
    "    #loop through string 'Showing: 1 - 10 of 121 roles' and extract int vals into list\n",
    "        # make sure to change vals into integer int(i)\n",
    "    num_vals = [int(i) for i in counted_roles.split() if i.isdigit()]\n",
    "    # ([1, jobs_per_page, total_jobs])\n",
    "    jobs_per_page = num_vals[1] \n",
    "    total_jobs = num_vals[-1]\n",
    "    # print(jobs_per_page, total_jobs)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # TODO: Locate the next page button and navigate to the next page if it exists\n",
    "\n",
    "        # all_links param can be used to possibly check current page for links that fit criteria before moving onto next page\n",
    "        #   but it doesn't seem all too necessary because clicking load more doesnt\n",
    "\n",
    "        # loop through all links on current page specifically for job links \n",
    "            # add vals for total number of jobs on curr page\n",
    "        job_link_count = sum('jobid' in link['href'] for link in all_links) \n",
    "        # print(job_link_count, jobs_per_page)\n",
    "        \n",
    "        # if total number of jobs on page == total number of jobs => BREAK LOOP & return\n",
    "        if job_link_count == total_jobs:\n",
    "            outer_loop_break = True\n",
    "            return page, outer_loop_break\n",
    "        \n",
    "        # locate load_more button, wait 10 for page to load\n",
    "        load_more = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.btn.btn--cta')))\n",
    "        # print(load_more[0].text)\n",
    "\n",
    "        # if load_more button exists,\n",
    "        if load_more:\n",
    "            # not 100% sure why yet, but load_more returns array -- need first elem of array\n",
    "            load_more_buttons = load_more[0] # JS: grab first element of list of ALL 'load_more'\n",
    "            # print(\"found button!\")\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'a.btn.btn--cta'))) #check for button clickability\n",
    "            driver.execute_script('arguments[0].scrollIntoView(true);', load_more_buttons) #scroll to load more button // went with JS method\n",
    "            driver.execute_script('arguments[0].click();', load_more_buttons) # click load more button\n",
    "            # wait for new content to load\n",
    "            time.sleep(5) #5 might be kinda long but better to be safe\n",
    "            \n",
    "        else:\n",
    "            # print('non found')\n",
    "            # PROBLEM: why are we skipping this else ..., skips to excpetion instead.\n",
    "                # SOLUTION: check for total num jobs == total num jobs on curr page\n",
    "            outer_loop_break = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while trying to click the 'next page' button: {e}\")\n",
    "        outer_loop_break = True\n",
    "    return page + 1, outer_loop_break\n",
    "\n",
    "# WebDriver setup\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "# options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(base_url)\n",
    "\n",
    "# Initialize variables\n",
    "job_links = []\n",
    "prev_page = 0\n",
    "page = 1\n",
    "\n",
    "# Main scraping loop\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    outer_loop_break = False\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    all_links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "    # Scrape job links\n",
    "    job_links = pull_company_name(base_url, all_links, job_links)\n",
    "\n",
    "    # Handle pagination\n",
    "    page, outer_loop_break = button_company_name(driver, page, outer_loop_break, all_links)\n",
    "\n",
    "    if outer_loop_break:\n",
    "        break\n",
    "\n",
    "# Output the collected job links\n",
    "print(\"Collected job links:\", job_links)\n",
    "# make sure im getting total num (121), no copies\n",
    "# print(len(job_links))\n",
    "\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
